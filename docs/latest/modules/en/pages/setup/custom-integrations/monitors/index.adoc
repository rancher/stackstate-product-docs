= Add a monitor to components
:revdate: 2025-07-10
:page-revdate: {revdate}
:description: SUSE Observability

== Overview

{stackstate-product-name} provides xref:/use/alerting/k8s-monitors.adoc[monitors out of the box], which provide monitoring on common issues that can occur in a Kubernetes cluster. It's also possible to configure custom monitors for the metrics collected by {stackstate-product-name} or application metrics ingested xref:/use/metrics/k8s-prometheus-remote-write.adoc[from Prometheus].

== Creating a monitor

Steps to create a monitor:

. <<_write_the_outline_of_the_monitor,Write the outline of the monitor>>
. <<_bind_the_results_of_the_monitor_to_the_correct_components,Bind the results of the monitor to the correct component>>
. <<_write_the_remediation_hint,Write the remediation hint>>

As an example the steps will add a monitor for the `Replica counts` of Kubernetes deployments.

=== Write the outline of the monitor

Open the `monitors.yaml` YAML file of your StackPack in your favorite code editor to change it throughout this guide. You can use the CLI to xref:/setup/custom-integrations/develop.adoc#_test_your_stackpack[Test Your StackPack].

For example, this could be the start for a monitor which monitors the available replicas of a deployment:

----
- _type: Monitor
  arguments:
    metric:
      query: "kubernetes_state_deployment_replicas_available"
      unit: "short"
      aliasTemplate: "Deployment replicas"
    comparator: "LTE"
    threshold: 0.0
    failureState: "DEVIATING"
    urnTemplate:
  description: "Monitor whether a deployment has replicas.
  function: {{ get "urn:stackpack:kubernetes-v2:shared:monitor-function:threshold"  }}
  identifier: urn:stackpack:my-stackpack:monitor:deployment-has-replicas
  intervalSeconds: 30
  name: Deployment has replicas
  remediationHint:
  status: "ENABLED"
  tags:
  - "deployments"
----

The `urnTemplate` and `remediationHint` will be filled in the next steps.

=== Bind the results of the monitor to the correct components

The results of a monitor need to be bound to components in {stackstate-product-name}, to be visible and usable. The result of a monitor is bound to a component using the component `identifiers`. Each component in {stackstate-product-name} has one or more identifiers that uniquely identify the component. To bind a result of a monitor to a component, it's required to provide the `urnTemplate`. The `urnTemplate` substitutes the labels in the time series of the monitor result into the template, producing an identifier matching a component. This is best illustrated with the example:

The metric that's used in this example is the `kubernetes_state_deployment_replicas_available` metric. Run the metric in the metric explorer to observe what labels are available on the time series:

image::k8s/available-replicas-metric-inspector.png[The available replicas in the metric explorer]

In the above table it's shown the metric has labels like `cluster_name`, `namespace` and `deployment`.

Because the metric is observed on deployments, it's most logical to bind the monitor results to deployment components. To do this, it's required to understand how the identifiers for deployments are constructed:

. In the UI, navigate to the `deployments` view and select a single deployment.
. Open the `Topology` view, and click the deployment component.
. When expanding the `Properties` in the right panel of the screen, the identifiers will show after hovering as shown below:

image::k8s/component-identifier.png[Finding a component identifier]

The identifier is shown as `urn:kubernetes:/preprod-dev.preprod.stackstate.io:calico-system:deployment/calico-typha`. This shows that the identifier is constructed based on the cluster name, namespace and deployment name. Knowing this, it's now possible to construct the `urnTemplate`:

----
  ...
  urnTemplate: "urn:kubernetes:/${cluster_name}:${namespace}:deployment/${deployment}"
  ...
----

<<_verifying_the_results_of_a_monitor,To verify>> whether the `urnTemplate` is correct, is explained further below.

=== Write the remediation hint

The remediation hint is there to help users find the cause of an issue when a monitor fires. The remediation hint is written in https://en.wikipedia.org/wiki/Markdown[markdown]. It's also possible to use the labels that are on the time series of the monitor result using a handlebars template, as in the following example:

----
  ...
  remediationHint: |-
    To remedy this issue with the deployment {{ labels.deployment }}, consider taking the following steps:

    1. Look at the logs of the pods created by the deployment
  ...
----

To offer a remediation experience that conforms to that offered by the standard {stackstate-product-name} monitors, follow the xref:/setup/custom-integrations/monitors/remediation-guide.adoc#_guidelines[Remediation guide guidelines].

== Testing the monitor

After you have made a monitor, validate whether it produces the expected results. The following steps can be taken:

. <<_create_or_update_the_monitor_in_suse_observability,Create or update the monitor in {stackstate-product-name}>>
. <<_verifying_the_results_of_a_monitor,Verify the monitor produces the expected result>>

=== Create or update the monitor in {stackstate-product-name}

- Use the xref:/setup/custom-integrations/develop.adoc#_test_your_stackpack[Test Your StackPack] command to deploy the StackPack.
+
[source,bash]
----
sts stackpack test -d ./my-stackpack --yes
----

=== Verifying the results of a monitor

==== Verify the execution of the monitor

Go to the monitor overview page (http://your-instance/#/monitors) and find your monitor.

. Verify the `Status` column is in `Enabled` state. If the monitor is in `Disabled` state, xref:/setup/custom-integrations/monitors/cli.adoc#_enable_or_disable_the_monitor[enable it]. If the status is in `Error` state, you can xref:/setup/custom-integrations/monitors/troubleshooting.adoc#_the_monitor_is_showing_an_error_in_the_monitor_status_overview[troubleshoot the error] using the CLI.
. Verify you see the expected number of states in the `Clear`/`Deviating`/`Critical` column. If this number is significantly lower or higher than the number of components you meant to monitor, the PromQL query might be giving too many results.

==== Verify the binding of the monitor

Observe whether the monitor is producing a result on one of the components that it's meant to monitor for. If the monitor doesn't show up, follow xref:/setup/custom-integrations/monitors/troubleshooting.adoc#_the_result_of_the_monitor_isnt_showing_on_a_component[these steps] to remedy.
