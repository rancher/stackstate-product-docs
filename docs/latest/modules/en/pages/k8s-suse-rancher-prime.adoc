= {stackstate-product-name}
:revdate: 2025-07-25
:page-revdate: {revdate}
:description: {stackstate-product-name}

== Introduction

{stackstate-product-name}, formerly known as StackState can be used for Observability of your Kubernetes clusters and their workloads.

The installation of {stackstate-product-name}, the {stackstate-product-name} UI extension and the {stackstate-product-name} Agents takes about 30 minutes in total.

== Getting help

For support please file a support case in https://scc.suse.com/[SUSE Customer Center (SCC)].

== Prerequisites

=== License key

A license key for {stackstate-product-name} server can be obtained via the SUSE Customer Center in the Subscription tab and will be shown as "{stackstate-product-name}" Registration Code. This license is valid until the end of your Rancher Prime subscription.

=== Requirements

To install {stackstate-product-name}, ensure that the cluster has enough CPU and memory capacity. Below are the specific requirements.

There are different installation options available for {stackstate-product-name}. It is possible to install {stackstate-product-name} either in a High-Availability (HA) or single instance (non-HA) setup. The non-HA setup is recommended for testing purposes or small environments. For production environments, it is recommended to install {stackstate-product-name} in a HA setup.

The HA production setup can support from 150 up to 4000 observed nodes. An observed node in this sizing table is taken to be 4 vCPUs and 16GB of memory, our `default node size`.
If nodes in your observed cluster are bigger, they can count for multiple `default nodes`, so a node of 12vCPU and 48GB counts as 3 `default nodes` under observation when picking
a profile.
The Non-HA setup can support up to 100 `default nodes` under observation.


The following table describes the resources required to deploy the {stackstate-product-name} server in a cluster, given the amount of `default nodes` that will be observed and whether the installation should be HA or not.

|===
|  | trial | 10 non-HA | 20 non-HA | 50 non-HA | 100 non-HA | 150 HA | 250 HA | 500 HA | 4000 HA

| *CPU Requests (cores)*
| 6.945
| 6.945
| 9.245
| 13.945
| 23.545
| 49.245
| 61.245
| 84.745
| 210.05

| *CPU Limits (cores)*
| 15.02
| 15.02
| 19.32
| 28.72
| 47.87
| 104
| 127
| 175.38
| 278.95

| *Memory Requests*
| 23180Mi
| 23180Mi
| 27056Mi
| 31582Mi
| 48088Mi
| 129958Mi
| 142426Mi
| 161106Mi
| 264330Mi

| *Memory Limits*
| 23718Mi
| 23718Mi
| 27708Mi
| 31614Mi
| 48120Mi
| 134762Mi
| 147030Mi
| 165910Mi
| 327550Mi

| *Storage*
| 153613Mi
| 338957Mi
| 379917Mi
| 482317Mi
| 533517Mi
| 2654430Mi
| 2756950Mi
| 3678260Mi
| 7159862Mi
|===

NOTE: An additional 20% of resources is required for pod (unequal) distribution, control plane, and agent installs.

[NOTE]
====
The requirement shown for profile represent the total amount of resources needed to run the {stackstate-product-name} server.
To ensure that all different services of Suse Observability server can be allocated:

* For non-HA installations the minimum per-node size is 4VCPU, 8GB
* For HA installations up to 500 nodes the minimum per-node size is 8VCPU, 16GB
* For 4000 nodes HA installations the minimum per-node size is 16VCPU, 32GB
====


[NOTE]
====
A trial setup is a 10 non-HA setup configured with a 3 day retention and lower disk space requirements.
====


These are just the upper and lower bounds of the resources that can be consumed by {stackstate-product-name} in the different installation options. The actual resource usage will depend on the features used, configured resource limits and dynamic usage patterns, such as Deployment or DaemonSet scaling. For our Rancher Prime customers, we recommend to start with the default requirements and monitor the resource usage of the {stackstate-product-name} components.

[NOTE]
====
The minimum requirements do not include spare CPU/Memory capacity to ensure smooth application rolling updates.
====


=== Storage

{stackstate-product-name} uses persistent volume claims for the services that need to store data. The default storage class for the cluster will be used for all services unless this is overridden by values specified on the command line or in a `values.yaml` file. All services come with a pre-configured volume size that should be good to get you started, but can be customized later using variables as required.

[NOTE]
====
{stackstate-product-name} requires the underlying storage to be based on flash memory (SSD) or similar in performance.
====

[NOTE]
====
For production environments, NFS is not recommended and supported for storage provisioning in {stackstate-product-name} due to the potential risk of data corruption.
====


For our different installation profiles, the following are the defaulted storage requirements:

|===
|  | trial | 10 non-HA | 20 non-HA | 50 non-HA | 100 non-HA | 150 HA | 250 HA | 500 HA | 4000 HA

| *Retention (days)*
| 3
| 30
| 30
| 30
| 30
| 30
| 30
| 30
| 30

| *Storage requirement*
| 125GB
| 280GB
| 420GB
| 420GB
| 600GB
| 2TB
| 2TB
| 2.5TB
| 5.5TB
|===

For more details on the defaults used, see the page xref:/setup/install-stackstate/kubernetes_openshift/storage.adoc[Configure storage].

=== Helm

{stackstate-product-name} is installed through Helm, which needs to be installed with a minimum version of 3.13.1.

=== The different components

==== {stackstate-product-name} Server

This is the on-prem hosted server part of the installation. It contains a set of services to store observability data:

* Topology (StackGraph)
* Metrics (VictoriaMetrics)
* Traces (ClickHouse)
* Logs (ElasticSearch)

Next to this, it contains a set of services for all the observability tasks. e.g. Notifications, State management, Monitoring, etc.

==== {stackstate-product-name} Agent

The lightweight {stackstate-product-name} agent is installed on your downstream worker nodes. It collects and reports metrics, events, traces and logs, and it provides real-time observability and insights, enabling proactive monitoring and troubleshooting of your IT environment.

The {stackstate-product-name} version of the Agent also uses eBPF as a lightweight way to monitor all your workloads and their communication. It also decodes the RED (Rate, Errors and Duration) signals for most of the common L7 protocols like TCP, HTTP, TLS, Redis, etc.

==== Rancher Prime - Observability UI extension

This is an UI extension to Rancher Manager that integrates the health signals observed by {stackstate-product-name}. It gives direct access to the health of any resource and a link to {stackstate-product-name}'s UI for further investigation.

=== Where to install {stackstate-product-name} server

{stackstate-product-name} server should be installed in its own downstream cluster intended for Observability. See the below picture for reference.

For {stackstate-product-name} to be able to work properly it needs:

* https://ranchermanager.docs.rancher.com/how-to-guides/new-user-guides/manage-clusters/create-kubernetes-persistent-storage[Kubernetes Persistent Storage] to be available in the observability cluster to store metrics, events, etc.
* the observability cluster to support a way to expose {stackstate-product-name} on an HTTPS URL to Rancher, {stackstate-product-name} users and the {stackstate-product-name} agent. This can be done via an Ingress configuration using an ingress controller, alternatively a (cloud) loadbalancer for the {stackstate-product-name} services could do this too, for more information see the https://ranchermanager.docs.rancher.com/how-to-guides/new-user-guides/kubernetes-resources-setup/load-balancer-and-ingress-controller[Rancher docs].

image::k8s/prime/SUSEObservabilityDeployment.png[Architecture]

=== Pre-Installation

Before installing the {stackstate-product-name} server a default storage class must be set up in the cluster where the {stackstate-product-name} server will be installed:

* *For k3s*: The local-path storage class of type rancher.io/local-path is created by default.
* *For EKS, AKS, GKE* a storage class is set by default
* *For RKE2 Node Drivers*: No storage class is created by default. You will need to create one before installing {stackstate-product-name}.

== Installing {stackstate-product-name}

[NOTE]
====
*Good to know*

If you created the cluster using Rancher Manager and would like to run the provisioning commands below from a local terminal instead of in the web terminal, just copy or download the kubeconfig from the cluster dashboard, see image below, and paste it (or place the downloaded file) into a file that you can easily find e.g. ~/.kube/config-rancher and set the environment variable KUBECONFIG=$HOME/.kube/config-rancher
====


image::k8s/prime/rancher_cluster_dashboard.png[Rancher]

After meeting the prerequisites you can proceed with the installation. The installation is NOT YET AVAILABLE from the app store. Instead, you can install {stackstate-product-name} via the kubectl shell of the cluster.

You can now follow the instruction below for a HA or NON-HA setup.

[NOTE]
====
Be aware upgrading or downgrading from HA to NON-HA and vice-versa is not yet supported.
====


=== Installation

. Get the helm chart
+
.helm_repo.sh
[,text]
----
helm repo add suse-observability https://charts.rancher.com/server-charts/prime/suse-observability
helm repo update
----

. Create configuration and deploy
+
[tabs]
====
Recommended method::
+
--
[NOTE]
=====
The `global.suseObservability` configuration method is available starting from version `2.8.0`. For earlier versions, use the legacy method.
=====

Create a `values.yaml` file with your configuration:

[source,yaml]
----
global:
  # Optional: Override image registry (defaults to registry.rancher.com)
  # Only needed for air-gapped environments or custom registries
  # imageRegistry: "your-private-registry.example.com"

  suseObservability:
    # Required: Your {stackstate-product-name} license key
    license: "YOUR-LICENSE-KEY"

    # Required: Base URL for {stackstate-product-name}
    baseUrl: "https://observability.example.com"

    # Required: Sizing profile
    # Available: trial, 10-nonha, 20-nonha, 50-nonha, 100-nonha,
    #            150-ha, 250-ha, 500-ha, 4000-ha
    sizing:
      profile: "150-ha"

    # Required: Admin password (must be bcrypt hash)
    # Generate with: htpasswd -bnBC 10 "" "your-password" | tr -d ':\n'
    adminPassword: "$2a$10$..."

    # Optional: Receiver API key (auto-generated if not provided)
    # receiverApiKey: "your-receiver-api-key"

    # Optional: Affinity for pod scheduling (see affinity documentation)
    # affinity:
    #   nodeAffinity: ...
    #   podAntiAffinity:
    #     requiredDuringSchedulingIgnoredDuringExecution: true
----

The `baseUrl` must be the URL via which {stackstate-product-name} will be accessible to Rancher, users, and the {stackstate-product-name} agent. The URL must include the scheme, for example `+https://observability.internal.mycompany.com+`. See also <<_accessing_suse_observability,accessing {stackstate-product-name}>>.

The `sizing.profile` should be one of trial, 10-nonha, 20-nonha, 50-nonha, 100-nonha, 150-ha, 250-ha, 500-ha, 4000-ha. Based on this profile, resources and configuration are automatically applied for HA or non-HA mode. Currently moving from a non-HA to an HA environment is not possible, so if you expect your environment will require observing around 150 nodes, select an HA profile immediately.

TIP: To generate a bcrypt password hash, use: `htpasswd -bnBC 10 "" "your-password" | tr -d ':\n'`

Deploy with a single command:

.helm_deploy.sh
[,text]
----
helm upgrade --install \
    --namespace suse-observability \
    --create-namespace \
    --values values.yaml \
    suse-observability \
    suse-observability/suse-observability
----

Alternatively, deploy directly using `--set` flags without a values file:

[,bash]
----
helm upgrade --install \
    --namespace suse-observability \
    --create-namespace \
    --set global.suseObservability.license="YOUR-LICENSE-KEY" \
    --set global.suseObservability.baseUrl="https://observability.example.com" \
    --set global.suseObservability.sizing.profile="150-ha" \
    --set global.suseObservability.adminPassword='$2a$10$...' \
    suse-observability \
    suse-observability/suse-observability
----

[WARNING]
=====
Using a single default password is great to get started with {stackstate-product-name}, but for a production setup xref:/setup/security/authentication/authentication_options.adoc[more secure authentication options] are available.
=====

[NOTE]
=====
For affinity configuration options, refer to xref:/setup/install-stackstate/kubernetes_openshift/affinity.adoc[Configure Kubernetes Affinities].
=====
--
Legacy method (Deprecated)::
+
--
[WARNING]
=====
This method is deprecated. For new installations, use the recommended method above. For existing installations using this method, see the xref:/setup/upgrade-stackstate/migrate-to-global-mode.adoc[migration guide] to transition to the new configuration format.
=====

Generate helm chart values files:

.helm_template.sh
[,text]
----
export VALUES_DIR=.
helm template \
  --set license='<your license>' \
  --set baseUrl='<suse-observability-base-url>' \
  --set rancherUrl='<rancher-prime-base-url>' \
  --set sizing.profile='<sizing.profile>' \
  suse-observability-values \
  suse-observability/suse-observability-values --output-dir $VALUES_DIR
----

The `baseUrl` must be the URL via which {stackstate-product-name} will be accessible to Rancher, users, and the {stackstate-product-name} agent. The URL must include the scheme, for example `+https://observability.internal.mycompany.com+`. See also <<_accessing_suse_observability,accessing {stackstate-product-name}>>.

To see health information in Rancher using the UI extension, set the `rancherUrl` value to the URL of Rancher (to be precise, its Origin).

This command generates the files `$VALUES_DIR/suse-observability-values/templates/baseConfig_values.yaml`, `$VALUES_DIR/suse-observability-values/templates/sizing_values.yaml`, and `$VALUES_DIR/suse-observability-values/templates/affinity_values.yaml` containing the necessary configuration to install the {stackstate-product-name} Helm Chart.

[NOTE]
=====
The {stackstate-product-name} administrator password will be autogenerated by the above command and are output as comments in the generated `basicConfig.yaml` file. For more info, see xref:/setup/security/authentication/single_password.adoc[single password].
The actual values contain the `bcrypt` hashes of those passwords so that they're securely stored in the Helm release in the cluster.
=====

[WARNING]
=====
Using a single default password is great to get started with {stackstate-product-name}, but for a production setup xref:/setup/security/authentication/authentication_options.adoc[more secure authentication options] are available.
=====

[NOTE]
=====
Store the generated `basicConfig.yaml`, `sizing_values.yaml` and `affinity_values.yaml` files safely. You can reuse these files for upgrades, which saves time and ensures that {stackstate-product-name} continues to use the same API key. This is desirable as it means Agents and other data providers for {stackstate-product-name} won't need to be updated.
The files can be regenerated independently using the switches `basicConfig.generate=false` and `sizing.generate=false` to disable any of them while keeping the previously generated version of the file in the `output-dir`.
=====

[NOTE]
=====
The {stackstate-product-name} Values chart generates affinity configurations you can use with the main {stackstate-product-name} chart to control pod scheduling behavior. Refer to xref:/setup/install-stackstate/kubernetes_openshift/affinity.adoc[Configure Kubernetes Affinities] for more information.
=====

. Configure {stackstate-product-name} to use Rancher as an OIDC provider.

    Generate the `oidc_values.yaml`. This guide assumes that you save it in the `$VALUES_DIR`

+
.$VALUES_DIR/oidc_values.yaml
[,yaml]
----
stackstate:
  authentication:
    rancher:
      clientId: "<oidc-client-id>"
      secret: "<oidc-secret>"
      baseUrl: "<rancher-url>"
----
+
[NOTE]
=====
This step is required if you are planning to use the Rancher RBAC to scope visibility into the downstream clusters.
For a more detailed explanation on how to configure {stackstate-product-name} to use Rancher as an OIDC provider, see xref:/setup/security/authentication/oidc.adoc#_rancher[Configure {stackstate-product-name} for using Rancher as an OIDC provider].
=====

. Deploy the {stackstate-product-name} helm chart with the generated values:

.helm_deploy.sh
[,text]
----
helm upgrade --install \
    --namespace suse-observability \
    --create-namespace \
    --values $VALUES_DIR/suse-observability-values/templates/baseConfig_values.yaml \
    --values $VALUES_DIR/suse-observability-values/templates/sizing_values.yaml \
    --values $VALUES_DIR/suse-observability-values/templates/affinity_values.yaml \
    --values $VALUES_DIR/oidc_values.yaml \
    suse-observability \
    suse-observability/suse-observability
----
--
====


== Accessing {stackstate-product-name}

The {stackstate-product-name} Helm chart has support for creating an Ingress resource to make {stackstate-product-name} accessible outside of the cluster. Follow xref:/setup/install-stackstate/kubernetes_openshift/ingress.adoc[these instructions] to set that up when you have an ingress controller in the cluster. Make sure that the resulting URL uses TLS with a valid, not self-signed, certificate.

If you prefer to use a load balancer instead of ingress, expose the `suse-observability-router` service. The URL for the loadbalancer needs to use a valid, not self-signed, TLS certificate.

== Installing UI extensions

To install UI extensions, enable the UI extensions from the rancher UI

image::k8s/prime/ui_extensions.png[Install]

After enabling UI extensions, follow these steps:

. Navigate to extensions on the rancher UI and under the "Available" section of extensions, you will find the Observability extension.
. Install the Observability extension.
. Once installed, on the left panel of the rancher UI, the _{stackstate-product-name}_ section appears.
. Navigate to the _{stackstate-product-name}_ section and select "configurations". In this section, you can add the {stackstate-product-name} server details and connect it.
. Follow the instructions as mentioned in _Obtain a service token_ section below and fill in the details.

=== Obtain a service token:

. Log into the {stackstate-product-name} instance.
. From the top left corner, select CLI.
. Note the API token and install {stackstate-product-name} cli on your local machine.
. Create a service token by running


----
sts service-token create --name suse-observability-extension --roles stackstate-k8s-troubleshooter
----


=== {stackstate-product-name} Rancher UI extension compatibility matrix

|===
| UI Extension Version | Supported Rancher Version

| 0.x.x
| 2.8

| 1.x.x
| 2.9

| 2.x.x
| 2.10 +
2.11 +
2.12
|===

== Installing the {stackstate-product-name} Agent

. In the {stackstate-product-name} UI open the main menu and select StackPacks.
. Select the Kubernetes StackPack.
. Click on new instance and provide the cluster name of the downstream cluster which you are adding. Make sure you match the name of the Rancher cluster with the name provided here. Click install.
. In the list of instructions find the section that matches your cluster best
. Execute the instructions provided to install the agent, these can be run in the `kubectl shell` that you can open for your cluster via the Rancher UI. But it can also be run from a local machine if it has Helm installed and is authorized to connect to the cluster.
. After you install the agent, the cluster can be seen within the {stackstate-product-name} UI as well as the _SUSE Rancher - Observability UI extension_.

== Required privileges

The deployment of the {stackstate-product-name} agent requires the following system privileges:

. `hostPID: true`: This privilege is required to associate process identifiers (PIDs) with their corresponding control groups (cgroups). This association is essential for accurately mapping processes to their respective containers.
. `hostNetwork: true` (Optional): By default, the node agent runs with `hostNetwork: true` to facilitate scraping of open metrics data from all configured pods on the node without requiring additional network policies. If disabled, appropriate network policies must be defined to ensure the agent can access the necessary endpoints.
. `securityContext.privileged: true`: This elevated privilege is required for several critical functions. Primarily, it permits the agent to inject eBPF (extended Berkeley Packet Filter) programs into each network namespace for monitoring purposes. It is also necessary for reading the connection tracking (conntrack) tables across all network namespaces. While this list is not exhaustive, future development aims to replace this broad privilege with more granular Linux capabilities where feasible.

Furthermore, the agent requires container runtime sockets to be mounted within its pod. This configuration is essential as it facilitates direct communication with the container runtime daemons, which is a prerequisite for scraping metrics and metadata from all containers on the host system.

== Rancher-Restricted PSA Template

The `Rancher-restricted` configuration (link:https://ranchermanager.docs.rancher.com/how-to-guides/new-user-guides/authentication-permissions-and-global-configuration/psa-config-templates[Pod Security Admission (PSA) Configuration Templates]) is a highly restrictive setup that aligns with current best practices for securing pods.

When running Rancher on a Kubernetes cluster that enforces a restrictive security policy by default, there are two ways to install the SUSE Observability Helm chart:

* *Exempt the entire chart namespace*, along with other link:https://ranchermanager.docs.rancher.com/how-to-guides/new-user-guides/authentication-permissions-and-global-configuration/psa-config-templates#exempting-required-rancher-namespaces[required Rancher namespaces].
* *Disable the privileged Elasticsearch init container* by setting `elasticsearch.sysctlInitContainer.enabled` to `false`. This requires you to manually increase the link:https://www.elastic.co/docs/deploy-manage/deploy/self-managed/vm-max-map-count[virtual memory settings] (`vm.max_map_count`) on the nodes. See also xref:/setup/install-stackstate/kubernetes_openshift/required_permissions.adoc#_elasticsearch[Elasticsearch Required Permissions]. 

Since the SUSE Observability Agent must run in privileged mode, the recommended approach is to install it into a namespace that you plan to exempt from the restrictive policy.

[NOTE]
====
All SUSE Observability Helm chart containers are configured with the following `securityContext` settings starting from version `v2.3.8` and onwards:

. `securityContext.capabilities.drop` is `["ALL"]`
. `securityContext.seccompProfile.type` is `"RuntimeDefault"`
. `securityContext.runAsNonRoot` is `true`
. `securityContext.allowPrivilegeEscalation` is `false`
====

== Single Sign On

To enable Single sign-on with your own authentication provider please xref:/setup/security/authentication/authentication_options.adoc[see here].

== Frequently asked questions & Observations:

. Is it mandatory to install a {stackstate-product-name} agent before proceeding with adding the UI extension?
 ** No this is not mandatory, the UI extension can be installed independent.
. Is it mandatory to install {stackstate-product-name} Server before we proceed with UI extensions?
 ** Yes this is mandatory since you need to provide a {stackstate-product-name} endpoint in the configuration
. Can we install {stackstate-product-name} on a local cluster or on a downstream cluster?
 ** Both options are possible.
. To monitor the downstream clusters, should we install the {stackstate-product-name} agent from the app store or add a new instance from the {stackstate-product-name} UI?
 ** Both options are possible depending on users preference.

== Open Issues

. When you uninstall and reinstall the UI extensions for Observability, we noticed that service token is not deleted and is reused upon reinstallation. Whenever we uninstall the extensions, service token should be removed.
 ** This information should be deleted when the UI extensions are uninstalled.
. After the extensions are installed, the {stackstate-product-name} UI opens in the same tab as the Rancher UI.
 ** You can use shift-click to open in a new tab, this will become the default behaviour
. Be aware upgrading or downgrading from HA to NON-HA and vice-versa is not yet supported.

== Troubleshooting

For any queries regarding the installation of the UI extension for Observability, see xref:/setup/install-stackstate/extension-troubleshooting.adoc[Extension troubleshooting guide].